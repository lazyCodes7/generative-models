{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a12f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nightskies/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unet import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusion import Diffusion\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834555f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29e8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608f1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root = 'data/', train = True, download = True, transform = transform)\n",
    "test_dataset = datasets.CIFAR10(root = 'data/', train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fac21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 16, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9037c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, path, **kwargs):\n",
    "    grid = torchvision.utils.make_grid(images, **kwargs)\n",
    "    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n",
    "    im = Image.fromarray(ndarr)\n",
    "    im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c967e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78271c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    device = 'cpu',\n",
    "    lr = 1e-4,\n",
    "    img_size = 32,\n",
    "    epochs = 10,\n",
    "    \n",
    "):\n",
    "    \n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    diffusion = Diffusion(img_size=img_size, device=device)\n",
    "    for epoch in range(epochs):\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            for images, label in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                images = images.to(device)\n",
    "                t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "                x_t, noise = diffusion.sample_noise_image(images, t)\n",
    "                predicted_noise = model(x_t, t)\n",
    "                loss = criterion(noise, predicted_noise)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "        \n",
    "        sampled_images = diffusion.sample_initial_image(model, images.shape[0])\n",
    "        save_images(sampled_images, path = './runs/epoch{}_sampled_images.jpg'.format(epoch+1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2de1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████| 3125/3125 [1:20:25<00:00,  1.54s/batch, loss=0.00161]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Diffusion' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[0;32mIn [11], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, lr, img_size, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m         tepoch\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 28\u001b[0m sampled_images \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m(model, images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     29\u001b[0m save_images(sampled_images, path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/epoch\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_sampled_images.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Diffusion' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fa815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
